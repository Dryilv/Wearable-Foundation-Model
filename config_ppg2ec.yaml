train:
  # [微调策略]
  # 监督学习(翻译)比 MAE 预训练收敛快。
  # 建议先跑 30-50 epoch，观察验证集 Loss。
  epochs: 50             
  
  # [显存] 
  # 保持与预训练一致或略大，因为 Decoder 不需要处理 Mask Token，显存压力稍小。
  batch_size: 128          
  
  # [学习率]
  # 微调时 LR 应该比预训练小，防止破坏 Encoder 的权重。
  # 预训练是 1.5e-4，这里建议降到 1.0e-4 或 5e-5。
  base_lr: 3e-5         
  min_lr: 1.0e-6
  warmup_epochs: 3        #以此快速热身
  weight_decay: 0.05      
  clip_grad: 3.0          
  use_amp: True           
  
  log_interval: 50
  save_freq: 5
  
  # [路径] 修改为翻译任务的保存路径
  save_dir: "./checkpoint_ppg2ecg_trans"
  
  # [断点续训] 
  # 注意：这里是指“翻译任务”的断点。
  # 如果是第一次开始翻译训练，请留空。
  # 预训练的权重是通过命令行参数 --pretrained 传入的，不要填在这里。
  resume: ""              

data:
  index_path: "/home/bml/storage/mnt/v-044d0fb740b04ad3/org/WFM/model/SharedPhysioTFMAE/train_index.json"
  signal_len: 3000        
  num_workers: 16         

model:
  # --- 必须与预训练模型完全一致的参数 ---
  # 否则权重加载会报错
  cwt_scales: 64          
  patch_size_time: 50     
  patch_size_freq: 4      
  embed_dim: 768          
  depth: 12               
  num_heads: 12           
  mlp_rank_ratio: 0.5     
  decoder_embed_dim: 512  
  decoder_depth: 8        
  decoder_num_heads: 16   
  
  # --- [关键修改] 翻译任务特定参数 ---
  
  # 1. Mask Ratio 必须为 0.0
  # 我们需要 Encoder 看到完整的 PPG 信号来推断 ECG。
  mask_ratio: 0.0         
  
  # ... (cwt_scales, embed_dim, etc. 不变) ...
  
  # --- Loss 权重 ---
  # time_loss_weight 控制整个时域 Loss (MSE+Corr) 的权重
  # 建议设为 1.0 或 2.0
  time_loss_weight: 1.0
  
  # 【新增】Pearson Correlation Loss 权重
  # 控制 Corr Loss 相对于 MSE Loss 的重要性。
  # 建议 0.5 - 1.0。这会鼓励模型学习波形形态，而不是死扣相位。
  corr_loss_weight: 0.75