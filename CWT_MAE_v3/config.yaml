train:
  epochs: 100             
  
  # [显存优化] 压榨 80G 显存
  batch_size: 64       
  
  # [关键修改] 梯度累积步数
  # 有效 Batch Size = 48 * 8 = 384，保证 MAE 预训练的稳定性
  accum_iter: 1
  
  base_lr: 1.5e-4         
  min_lr: 1.0e-6
  warmup_epochs: 5        
  auto_scale_lr: True     
  
  weight_decay: 0.05      
  clip_grad: 3.0
  
  use_amp: True           
  
  log_interval: 50
  save_freq: 5
  save_dir: "./checkpoint_768_5channel_flash"
  
  resume: ""

data:
  index_path: "train_index_cleaned.json"
  # [关键修改] 统一对齐到 3000 点
  signal_len: 3000        
  num_workers: 16         
  use_sliding_window: False 
  window_stride: 1500      # 如果未来开启滑动窗口，步长设为长度的一半

model:
  cwt_scales: 64          
  
  # [关键修改] 避免 Token 爆炸
  # Time=30, Freq=8 -> Tokens = (3000/30) * (64/8) = 100 * 8 = 800 tokens/channel
  # 既保留了 0.3s 的精细时间分辨率，又将计算量控制在合理范围
  patch_size_time: 30     
  patch_size_freq: 8      
  use_conv_stem: True     
  
  embed_dim: 768          
  depth: 12               
  num_heads: 12           
  
  mlp_rank_ratio: 0.5     
  
  decoder_embed_dim: 512  
  decoder_depth: 8        
  decoder_num_heads: 16   
  
  # 配合 Tubelet Masking，0.6 是一个非常好的起点
  mask_ratio: 0.6         
  
  # 是否使用信号差分特征 (d1, d2)
  # True: 3通道 (原始+一阶+二阶), 精度更高但慢
  # False: 1通道 (原始), 速度极快, 显存占用低
  use_diff: False

  # [关键修改] 差分通道 Loss 权重
  # 仅在 use_diff: True 时生效
  # 建议降低差分信号的权重，因为它们含噪较大且难预测
  # 格式: [原始信号权重, 一阶差分权重, 二阶差分权重]
  diff_loss_weight: [1.0, 0.5, 0.1]

  # 新版代码中时域 Loss 仅计算 Mask 部分，数值会变小，0.1 可作为起点，视 wandb 曲线调整
  time_loss_weight: 0.1
  
  data_ratio: 1.0