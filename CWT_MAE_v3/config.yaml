train:
  # 2w 小时数据量巨大，建议先跑 100 epoch 观察 Loss 收敛情况
  epochs: 100             
  
  # [显存优化与 Batch Size] 
  # v3 (1D Pixel-based) 显存占用比 v1/v2 (2D CWT) 低得多。
  # Token 数量: 3000 / 4 = 750 (远小于 v2 的 960 或 v1 的 800)
  # 可以开大 Batch Size
  batch_size: 256          
  
  # 学习率策略
  base_lr: 1.5e-4         
  min_lr: 1.0e-6
  warmup_epochs: 5        
  
  # 正则化
  weight_decay: 0.05      
  clip_grad: 3.0          
  use_amp: True           
  
  # 日志与保存
  log_interval: 50
  save_freq: 5
  save_dir: "./checkpoint_pixel_mae_v3"
  resume: ""

data:
  index_path: "/home/bml/storage/mnt/v-044d0fb740b04ad3/org/WFM/model/SharedPhysioTFMAE/train_index.json"
  signal_len: 3000         # 30秒 @ 100Hz
  original_len: 3000      
  stride: null             # v3 默认处理长序列，不切片
  num_workers: 16         

model:
  # --- Pixel/Point 级别参数 ---
  # patch_size: 
  #   - 1: 纯 Pixel 级别 (Sequence Length = 3000)，计算量大但最精细
  #   - 4: 推荐值 (Sequence Length = 750)，效率与精度的平衡
  patch_size: 4           
  
  # --- CWT Loss 参数 ---
  # 虽然输入不使用 CWT，但我们用 CWT Loss 约束频域一致性
  # [消融实验设置]
  # - 1.0: 启用 CWT Loss (Dual-Objective)，验证“隐式频域约束”的有效性 (v3 Default)
  # - 0.0: 禁用 CWT Loss (Pure Time-Domain)，验证 Transformer 纯时域建模能力 (Baseline)
  cwt_scales: 64          
  cwt_loss_weight: 1.0    
  
  # --- Transformer Encoder (ViT-Base 规模) ---
  embed_dim: 768          
  depth: 12               
  num_heads: 12           
  
  # --- 张量分解参数 ---
  mlp_rank_ratio: 0.5     
  
  # --- Decoder ---
  decoder_embed_dim: 512  
  decoder_depth: 8        
  decoder_num_heads: 16   
  
  # --- 训练策略 ---
  # 1D 信号通常需要高 Mask Ratio
  mask_ratio: 0.75         
