import torch
from torch import nn
from transformers import T5Config, T5EncoderModel


class MOMENTPretrain(nn.Module):
    def __init__(self, config_size='base', seq_len=512, patch_len=8):
        super().__init__()

        # ====================================================
        # 1. é…ç½®æ¨¡å‹è§„æ¨¡ (Small / Base / Large)
        # ====================================================
        if config_size == 'small':
            d_model = 512
            n_layers = 6
            n_heads = 8
            d_ff = 2048
        elif config_size == 'base':
            d_model = 768
            n_layers = 12
            n_heads = 12
            d_ff = 3072
        elif config_size == 'large':
            d_model = 1024
            n_layers = 24
            n_heads = 16
            d_ff = 4096
        else:
            raise ValueError("config_size must be 'small', 'base', or 'large'")

        # ====================================================
        # 2. å®šä¹‰æ ¸å¿ƒç»„ä»¶
        # ====================================================
        self.seq_len = seq_len
        self.patch_len = patch_len
        self.n_patches = seq_len // patch_len  # 512/8 = 64

        # A. Patch Embedding å±‚
        self.patch_embedding = nn.Linear(patch_len, d_model)

        # B. Mask Token
        self.mask_token = nn.Parameter(torch.randn(1, 1, d_model))

        # C. éª¨å¹²ç½‘ç»œ (T5 Encoder)
        config = T5Config(
            d_model=d_model,
            num_layers=n_layers,
            num_heads=n_heads,
            d_kv=d_model // n_heads,
            d_ff=d_ff,
            dropout_rate=0.1,
            vocab_size=1,
            use_cache=False
        )
        self.encoder = T5EncoderModel(config)

        # D. é‡å»ºå¤´
        self.head = nn.Linear(d_model, patch_len)

        # E. æŸå¤±å‡½æ•° (å®šä¹‰åœ¨è¿™é‡Œæ›´è§„èŒƒ)
        self.loss_fct = nn.MSELoss()

    def forward(self, x, mask=None):
        """
        è¾“å…¥:
        - x: [Batch, N_Patches, Patch_Len]
        - mask: [Batch, N_Patches] (True è¡¨ç¤ºè¢«æ©ç›–)
        """
        batch_size, n_patches, _ = x.shape

        # 1. æŠ•å½±: [B, N, P] -> [B, N, D]
        x_embed = self.patch_embedding(x)

        # 2. åº”ç”¨æ©ç 
        mask_tokens = self.mask_token.expand(batch_size, n_patches, -1)

        # å¦‚æœæä¾›äº† maskï¼Œåˆ™åº”ç”¨æ›¿æ¢é€»è¾‘
        if mask is not None:
            # mask æ‰©å±•ä¸º [B, N, D]
            mask_expanded = mask.unsqueeze(-1).expand_as(x_embed)
            # æ ¸å¿ƒæ›¿æ¢: Mask ä¸º True çš„åœ°æ–¹ç”¨ mask_token
            input_embeds = torch.where(mask_expanded, mask_tokens, x_embed)
        else:
            input_embeds = x_embed

        # 3. T5 Encoder
        outputs = self.encoder(inputs_embeds=input_embeds)
        hidden_states = outputs.last_hidden_state  # [B, N, D]

        # 4. é‡å»ºè¾“å‡º
        pred_patches = self.head(hidden_states)  # [B, N, P]

        # 5. è®¡ç®— Loss (åªè®¡ç®— Mask éƒ¨åˆ†)
        loss = torch.tensor(0.0, device=x.device)  # åˆå§‹åŒ– loss
        if mask is not None:
            # åˆ©ç”¨ PyTorch çš„å¸ƒå°”ç´¢å¼•ï¼Œç›´æ¥å–å‡ºè¢« Mask çš„éƒ¨åˆ†
            # target å½¢çŠ¶å˜æ›´ä¸º: [Total_Masked_Count, Patch_Len]
            target = x[mask]
            pred = pred_patches[mask]

            # è®¡ç®— MSE
            loss = self.loss_fct(pred, target)

        # è¿”å›å…ƒç»„: (Loss, é¢„æµ‹ç»“æœ)
        # è¿™ç¬¦åˆ HuggingFace å’Œå¸¸ç”¨è®­ç»ƒä¹ æƒ¯
        return loss, pred_patches


# # ====================================================
# # æµ‹è¯•ä»£ç  (ä¿®æ­£äº†å…ƒç»„è§£åŒ…é—®é¢˜)
# # ====================================================
# if __name__ == "__main__":
#     # 1. å®ä¾‹åŒ–
#     model = MOMENTPretrain(config_size='base')
#     print(f"âœ… æ¨¡å‹åˆå§‹åŒ–æˆåŠŸ | å‚æ•°é‡: {sum(p.numel() for p in model.parameters()) / 1e6:.2f} M")
#
#     # 2. æ¨¡æ‹Ÿæ•°æ®
#     batch_size = 32
#     dummy_input = torch.randn(batch_size, 64, 8)
#
#     # 3. æ¨¡æ‹Ÿæ©ç  (30% True)
#     dummy_mask = torch.rand(batch_size, 64) < 0.3
#
#     # 4. å‰å‘ä¼ æ’­
#     # ã€å…³é”®ä¿®æ”¹ã€‘è¿™é‡Œå¿…é¡»ç”¨ä¸¤ä¸ªå˜é‡æ¥æ”¶è¿”å›å€¼ï¼
#     loss, output = model(dummy_input, dummy_mask)
#
#     print(f"\nè¾“å…¥å½¢çŠ¶: {dummy_input.shape}")
#     print(f"è¾“å‡ºå½¢çŠ¶: {output.shape}")
#     print(f"Loss å€¼: {loss.item()}")
#
#     # 5. æ£€æŸ¥
#     assert output.shape == dummy_input.shape, "âŒ è¾“å…¥è¾“å‡ºå½¢çŠ¶ä¸åŒ¹é…ï¼"
#     assert not torch.isnan(loss), "âŒ Loss ä¸º NaNï¼Œæ£€æŸ¥æ•°æ®æˆ–å½’ä¸€åŒ–ï¼"
#
#     print("\nğŸ‰ æ¶æ„éªŒè¯é€šè¿‡ï¼")